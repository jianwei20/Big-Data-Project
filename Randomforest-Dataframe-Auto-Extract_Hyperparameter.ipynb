{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#source ~/.bashrc\n",
    "#http://localhost:4040/executors/   後台\n",
    "#pyspark --master local[*] --executor-memory 4G --driver-memory 2G --packages com.databricks:spark-csv_2.10:1.4.0\n",
    "#(加起來不要超過8  --executor-memory 2g   --driver-memory 2g 處理排程)\n",
    "#啟動pyspark指令：\n",
    "#pyspark --packages com.databricks:spark-csv_2.10:1.4.0\n",
    "#pyspark --packages com.databricks:spark-csv_2.10:1.4.0 --master local[*] --executor-memory 4G\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.ml.feature import RFormula\n",
    "\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.param import Param, Params\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer\n",
    "from pyspark.sql import Row\n",
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.mllib.util import MLUtils\n",
    "\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "\n",
    "from pyspark.ml.tuning import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import *\n",
    "\n",
    "# Load and parse the data file, converting it to a DataFrame.\n",
    "data = sqlContext.read.format(\"com.databricks.spark.csv\").options(header='true', inferschema='true').load(\"/home/sheng/Downloads/Click_Through_Rate_Prediction/Click_Through_Rate_Prediction/train10000.csv\")\n",
    "#data = sqlContext.read.format(\"com.databricks.spark.csv\").options(header='true', inferschema='true').load(\"/home/sheng/Downloads/Click_Through_Rate_Prediction/Click_Through_Rate_Prediction/train.csv\")\n",
    "# Displays the content of the DataFrame to stdout\n",
    "#df.show()\n",
    "#data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: decimal(20,0) (nullable = true)\n",
      " |-- click: integer (nullable = true)\n",
      " |-- hour: integer (nullable = true)\n",
      " |-- C1: integer (nullable = true)\n",
      " |-- banner_pos: integer (nullable = true)\n",
      " |-- site_id: string (nullable = true)\n",
      " |-- site_domain: string (nullable = true)\n",
      " |-- site_category: string (nullable = true)\n",
      " |-- app_id: string (nullable = true)\n",
      " |-- app_domain: string (nullable = true)\n",
      " |-- app_category: string (nullable = true)\n",
      " |-- device_id: string (nullable = true)\n",
      " |-- device_ip: string (nullable = true)\n",
      " |-- device_model: string (nullable = true)\n",
      " |-- device_type: integer (nullable = true)\n",
      " |-- device_conn_type: integer (nullable = true)\n",
      " |-- C14: integer (nullable = true)\n",
      " |-- C15: integer (nullable = true)\n",
      " |-- C16: integer (nullable = true)\n",
      " |-- C17: integer (nullable = true)\n",
      " |-- C18: integer (nullable = true)\n",
      " |-- C19: integer (nullable = true)\n",
      " |-- C20: integer (nullable = true)\n",
      " |-- C21: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the schema in a tree format\n",
    "data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------+----+----------+--------+-------------+\n",
      "|                  id|click|    hour|  C1|banner_pos| site_id|site_category|\n",
      "+--------------------+-----+--------+----+----------+--------+-------------+\n",
      "| 1000009418151094273|    0|14102100|1005|         0|1fbe01fe|     28905ebd|\n",
      "|10000169349117863715|    0|14102100|1005|         0|1fbe01fe|     28905ebd|\n",
      "|10000371904215119486|    0|14102100|1005|         0|1fbe01fe|     28905ebd|\n",
      "|10000640724480838376|    0|14102100|1005|         0|1fbe01fe|     28905ebd|\n",
      "|10000679056417042096|    0|14102100|1005|         1|fe8cc448|     0569f928|\n",
      "|10000720757801103869|    0|14102100|1005|         0|d6137915|     f028772b|\n",
      "|10000724729988544911|    0|14102100|1005|         0|8fda644b|     f028772b|\n",
      "|10000918755742328737|    0|14102100|1005|         1|e151e245|     f028772b|\n",
      "|10000949271186029916|    1|14102100|1005|         0|1fbe01fe|     28905ebd|\n",
      "|10001264480619467364|    0|14102100|1002|         0|84c7ba46|     50e219e0|\n",
      "|10001868339616595934|    0|14102100|1005|         1|e151e245|     f028772b|\n",
      "|10001966791793526909|    0|14102100|1005|         0|1fbe01fe|     28905ebd|\n",
      "|10002028568167339219|    0|14102100|1005|         0|9e8cf15d|     f028772b|\n",
      "|10002044883120869786|    0|14102100|1005|         0|d6137915|     f028772b|\n",
      "|10002518649031436658|    0|14102100|1005|         0|85f751fd|     50e219e0|\n",
      "|10003539039235338011|    0|14102100|1005|         0|1fbe01fe|     28905ebd|\n",
      "|10003585669470236873|    0|14102100|1005|         0|d9750ee7|     f028772b|\n",
      "|10004105575081229495|    0|14102100|1005|         0|1fbe01fe|     28905ebd|\n",
      "|10004181428767727519|    0|14102100|1005|         1|0c2fe9d6|     28905ebd|\n",
      "|10004482643316086592|    0|14102100|1005|         0|85f751fd|     50e219e0|\n",
      "+--------------------+-----+--------+----+----------+--------+-------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Select only the \"name\" column\n",
    "Schema = data.select(\"id\",\"click\",\"hour\",\"C1\",\"banner_pos\",\"site_id\",\"site_category\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Schema = StructType([\n",
    "      StructField(\"id\", DoubleType(), True),\n",
    "      StructField(\"click\", DoubleType(), True),\n",
    "      StructField(\"hour\", StringType(), True),\n",
    "      StructField(\"C1\", DoubleType(), True),\n",
    "      StructField(\"banner_pos\", DoubleType(), True),\n",
    "      StructField(\"site_id\", StringType(), True),\n",
    "      StructField(\"site_domain\", StringType(), True),\n",
    "      StructField(\"site_category\", StringType(), True),\n",
    "      StructField(\"app_id\", StringType(), True),\n",
    "      StructField(\"app_domain\", StringType(), True),\n",
    "      StructField(\"app_category\", StringType(), True),\n",
    "      StructField(\"device_id\", StringType(), True),\n",
    "      StructField(\"device_ip\", StringType(), True),\n",
    "      StructField(\"device_model\", StringType(), True),\n",
    "      #StructField(\"device_type\", DoubleType(), True),\n",
    "      #StructField(\"device_conn_type\", DoubleType(), True),\n",
    "      #StructField(\"C14\", DoubleType(), True),\n",
    "      #StructField(\"C15\", DoubleType(), True),\n",
    "      #StructField(\"C16\", DoubleType(), True),\n",
    "      #StructField(\"C17\", DoubleType(), True),\n",
    "      #StructField(\"C18\", DoubleType(), True),\n",
    "      #StructField(\"C19\", DoubleType(), True),\n",
    "      #StructField(\"C20\", DoubleType(), True),\n",
    "      #StructField(\"C21\", DoubleType(), True)\n",
    "        \n",
    "      StructField(\"device_type\", StringType(), True),\n",
    "      StructField(\"device_conn_type\", StringType(), True),\n",
    "      StructField(\"C14\", DoubleType(), True),\n",
    "      StructField(\"C15\", DoubleType(), True),\n",
    "      StructField(\"C16\", DoubleType(), True),\n",
    "      StructField(\"C17\", DoubleType(), True),\n",
    "      StructField(\"C18\", DoubleType(), True),\n",
    "      StructField(\"C19\", DoubleType(), True),\n",
    "      StructField(\"C20\", DoubleType(), True),\n",
    "      StructField(\"C21\", DoubleType(), True)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StructType(List(StructField(id,DoubleType,true),StructField(click,DoubleType,true),StructField(hour,StringType,true),StructField(C1,DoubleType,true),StructField(banner_pos,DoubleType,true),StructField(site_id,StringType,true),StructField(site_domain,StringType,true),StructField(site_category,StringType,true),StructField(app_id,StringType,true),StructField(app_domain,StringType,true),StructField(app_category,StringType,true),StructField(device_id,StringType,true),StructField(device_ip,StringType,true),StructField(device_model,StringType,true),StructField(device_type,StringType,true),StructField(device_conn_type,StringType,true),StructField(C14,DoubleType,true),StructField(C15,DoubleType,true),StructField(C16,DoubleType,true),StructField(C17,DoubleType,true),StructField(C18,DoubleType,true),StructField(C19,DoubleType,true),StructField(C20,DoubleType,true),StructField(C21,DoubleType,true)))\n"
     ]
    }
   ],
   "source": [
    "#data.printSchema()\n",
    "print Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----+--------+----+----------+--------+-----------+-------------+--------+----------+------------+---------+---------+------------+-----------+----------------+-----+---+---+----+---+---+------+---+-----+\n",
      "|                  id|click|    hour|  C1|banner_pos| site_id|site_domain|site_category|  app_id|app_domain|app_category|device_id|device_ip|device_model|device_type|device_conn_type|  C14|C15|C16| C17|C18|C19|   C20|C21|label|\n",
      "+--------------------+-----+--------+----+----------+--------+-----------+-------------+--------+----------+------------+---------+---------+------------+-----------+----------------+-----+---+---+----+---+---+------+---+-----+\n",
      "| 1000009418151094273|    0|14102100|1005|         0|1fbe01fe|   f3845767|     28905ebd|ecad2386|  7801e8d9|    07d7df22| a99f214a| ddd2926e|    44956a24|          1|               2|15706|320| 50|1722|  0| 35|    -1| 79|  0.0|\n",
      "|10000169349117863715|    0|14102100|1005|         0|1fbe01fe|   f3845767|     28905ebd|ecad2386|  7801e8d9|    07d7df22| a99f214a| 96809ac8|    711ee120|          1|               0|15704|320| 50|1722|  0| 35|100084| 79|  0.0|\n",
      "|10000371904215119486|    0|14102100|1005|         0|1fbe01fe|   f3845767|     28905ebd|ecad2386|  7801e8d9|    07d7df22| a99f214a| b3cf8def|    8a4875bd|          1|               0|15704|320| 50|1722|  0| 35|100084| 79|  0.0|\n",
      "|10000640724480838376|    0|14102100|1005|         0|1fbe01fe|   f3845767|     28905ebd|ecad2386|  7801e8d9|    07d7df22| a99f214a| e8275b8f|    6332421a|          1|               0|15706|320| 50|1722|  0| 35|100084| 79|  0.0|\n",
      "|10000679056417042096|    0|14102100|1005|         1|fe8cc448|   9166c161|     0569f928|ecad2386|  7801e8d9|    07d7df22| a99f214a| 9644d0bf|    779d90c2|          1|               0|18993|320| 50|2161|  0| 35|    -1|157|  0.0|\n",
      "|10000720757801103869|    0|14102100|1005|         0|d6137915|   bb1ef334|     f028772b|ecad2386|  7801e8d9|    07d7df22| a99f214a| 05241af0|    8a4875bd|          1|               0|16920|320| 50|1899|  0|431|100077|117|  0.0|\n",
      "|10000724729988544911|    0|14102100|1005|         0|8fda644b|   25d4cfcd|     f028772b|ecad2386|  7801e8d9|    07d7df22| a99f214a| b264c159|    be6db1d7|          1|               0|20362|320| 50|2333|  0| 39|    -1|157|  0.0|\n",
      "|10000918755742328737|    0|14102100|1005|         1|e151e245|   7e091613|     f028772b|ecad2386|  7801e8d9|    07d7df22| a99f214a| e6f67278|    be74e6fe|          1|               0|20632|320| 50|2374|  3| 39|    -1| 23|  0.0|\n",
      "|10000949271186029916|    1|14102100|1005|         0|1fbe01fe|   f3845767|     28905ebd|ecad2386|  7801e8d9|    07d7df22| a99f214a| 37e8da74|    5db079b5|          1|               2|15707|320| 50|1722|  0| 35|    -1| 79|  1.0|\n",
      "|10001264480619467364|    0|14102100|1002|         0|84c7ba46|   c4e18dd6|     50e219e0|ecad2386|  7801e8d9|    07d7df22| c357dbff| f1ac7184|    373ecbe6|          0|               0|21689|320| 50|2496|  3|167|100191| 23|  0.0|\n",
      "|10001868339616595934|    0|14102100|1005|         1|e151e245|   7e091613|     f028772b|ecad2386|  7801e8d9|    07d7df22| a99f214a| 5d877109|    8f5c9827|          1|               0|17747|320| 50|1974|  2| 39|100019| 33|  0.0|\n",
      "|10001966791793526909|    0|14102100|1005|         0|1fbe01fe|   f3845767|     28905ebd|ecad2386|  7801e8d9|    07d7df22| a99f214a| 6f407810|    1f0bc64f|          1|               0|15701|320| 50|1722|  0| 35|    -1| 79|  0.0|\n",
      "|10002028568167339219|    0|14102100|1005|         0|9e8cf15d|   0d3cb7be|     f028772b|ecad2386|  7801e8d9|    07d7df22| a99f214a| 58811cdf|    8326c04b|          1|               2|20596|320| 50|2161|  0| 35|100148|157|  0.0|\n",
      "|10002044883120869786|    0|14102100|1005|         0|d6137915|   bb1ef334|     f028772b|ecad2386|  7801e8d9|    07d7df22| a99f214a| 72aab6df|    04258293|          1|               0|19771|320| 50|2227|  0|687|100077| 48|  0.0|\n",
      "|10002518649031436658|    0|14102100|1005|         0|85f751fd|   c4e18dd6|     50e219e0|98fed791|  d9b5648e|    0f2161f8| a99f214a| 6dec2796|    aad45b01|          1|               0|20984|320| 50|2371|  0|551|    -1| 46|  0.0|\n",
      "|10003539039235338011|    0|14102100|1005|         0|1fbe01fe|   f3845767|     28905ebd|ecad2386|  7801e8d9|    07d7df22| a99f214a| a4f47b2e|    8a4875bd|          1|               0|15699|320| 50|1722|  0| 35|100084| 79|  0.0|\n",
      "|10003585669470236873|    0|14102100|1005|         0|d9750ee7|   98572c79|     f028772b|ecad2386|  7801e8d9|    07d7df22| a99f214a| 9b1fe278|    128f4ba1|          1|               0|17914|320| 50|2043|  2| 39|    -1| 32|  0.0|\n",
      "|10004105575081229495|    0|14102100|1005|         0|1fbe01fe|   f3845767|     28905ebd|ecad2386|  7801e8d9|    07d7df22| a99f214a| c26c53cf|    be87996b|          1|               2|15708|320| 50|1722|  0| 35|100084| 79|  0.0|\n",
      "|10004181428767727519|    0|14102100|1005|         1|0c2fe9d6|   27e3c518|     28905ebd|ecad2386|  7801e8d9|    07d7df22| a99f214a| b7a69808|    158e4944|          1|               0| 6558|320| 50| 571|  2| 39|    -1| 32|  0.0|\n",
      "|10004482643316086592|    0|14102100|1005|         0|85f751fd|   c4e18dd6|     50e219e0|66a5f0f3|  d9b5648e|    cef3e649| a99f214a| fa60af6b|    b4b19c97|          1|               0|21234|320| 50|2434|  3|163|100088| 61|  0.0|\n",
      "+--------------------+-----+--------+----+----------+--------+-----------+-------------+--------+----------+------------+---------+---------+------------+-----------+----------------+-----+---+---+----+---+---+------+---+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "## Index labels, adding metadata to the label column.\n",
    "## Fit on whole dataset to include all labels in index.\n",
    "data = StringIndexer(inputCol=\"click\", outputCol=\"label\").fit(data).transform(data)\n",
    "data.show()\n",
    "## 可產生另一個檔案.transform(data)不一定要在（data）檔案裡\n",
    "#labelIndexer  ===> data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'str'>\n"
     ]
    },
    {
     "ename": "IllegalArgumentException",
     "evalue": "u'Could not parse formula: \"label ~ id\"'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIllegalArgumentException\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-2fe1afff87e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     68\u001b[0m                 \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFeatureString\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0mformula\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRFormula\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformula\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFeatureString\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfeaturesCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"features\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabelCol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m                 \u001b[0mformula_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformula\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m                 \u001b[0mformula_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"features\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"label\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m#==\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sheng/Downloads/Spark/spark-2.0.2-bin-hadoop2.7/python/pyspark/ml/base.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, dataset, params)\u001b[0m\n\u001b[1;32m     62\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             raise ValueError(\"Params must be either a param map or a list/tuple of param maps, \"\n",
      "\u001b[0;32m/home/sheng/Downloads/Spark/spark-2.0.2-bin-hadoop2.7/python/pyspark/ml/wrapper.pyc\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 213\u001b[0;31m         \u001b[0mjava_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    214\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjava_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sheng/Downloads/Spark/spark-2.0.2-bin-hadoop2.7/python/pyspark/ml/wrapper.pyc\u001b[0m in \u001b[0;36m_fit_java\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    208\u001b[0m         \"\"\"\n\u001b[1;32m    209\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transfer_params_to_java\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 210\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_java_obj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    211\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    212\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sheng/Downloads/Spark/spark-2.0.2-bin-hadoop2.7/python/lib/py4j-0.10.3-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1133\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sheng/Downloads/Spark/spark-2.0.2-bin-hadoop2.7/python/pyspark/sql/utils.pyc\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m     77\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mQueryExecutionException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'java.lang.IllegalArgumentException: '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mIllegalArgumentException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m': '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstackTrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdeco\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIllegalArgumentException\u001b[0m: u'Could not parse formula: \"label ~ id\"'"
     ]
    }
   ],
   "source": [
    "#=================================================\n",
    "#Auto-Extract_Hyperparameter\n",
    "# RFormula\n",
    "from pyspark.ml.feature import RFormula\n",
    "#==\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.param import Param, Params\n",
    "from pyspark.ml.feature import HashingTF, Tokenizer\n",
    "from pyspark.sql import Row\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.ml.feature import StringIndexer, VectorIndexer\n",
    "from pyspark.mllib.classification import LogisticRegressionWithLBFGS\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.mllib.util import MLUtils\n",
    "#==\n",
    "#==\n",
    "from pyspark.mllib.linalg import Vectors\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.ml.param import Param, Params\n",
    "#==\n",
    "import sys\n",
    "import csv\n",
    "import re\n",
    "import os\n",
    "import itertools\n",
    "#==\n",
    "#==\n",
    "\n",
    "\n",
    "def FindSubsets(S,m):\n",
    "    #return set(itertools.combinations(S,m))\n",
    "    return list(itertools.combinations(S,m))\n",
    "\n",
    "f = open('/home/sheng/Downloads/Click_Through_Rate_Prediction/Click_Through_Rate_Prediction/train10000.csv', 'r')\n",
    "rows = csv.reader(f)\n",
    "Feature_supersets = {} #print(type) #dict\n",
    "for row in rows:\n",
    "\t#print(rows)  \n",
    "\t#print(type(rows)) #<type 'list'>\n",
    "\trow.remove(\"click\")\n",
    "\tfor n_feature in range(len(row)):\n",
    "\t\t#set(rows)\n",
    "\t\tresult=FindSubsets(row,n_feature) #n_feature+1\n",
    "\t\t#print(result)\n",
    "\t\tFeature_supersets[n_feature]=result #n_feature+1\n",
    "\tbreak\n",
    "#f.close()\n",
    "\n",
    "for i in Feature_supersets:\n",
    "\tFeatureString=\"\"\n",
    "\tfor j in Feature_supersets[i]:\n",
    "\t\tif (len(j) == 0) : continue\n",
    "\t\telse : string='\"label ~ '\n",
    "\t\tfor k in j:\n",
    "\t\t\tstring=string+k+' + '  ##using subfunction  #remove click\n",
    "\t\t\tFeatureString=string\n",
    "\t\tFeatureString=FeatureString[:-3]  #remove +\n",
    "\t\tFeatureString=FeatureString+'\"'  #add \"\"\n",
    "        #print(FeatureString)\n",
    "\t\t#/*do hyperparamater*/ \n",
    "        ## RFormula: string input colums will be one-hot encoded, and numeric columns will be cast to doubles.\n",
    "        ##特徵值要被修正formula\" \"\n",
    "#         formula = RFormula(\n",
    "#         formula=\"label ~ banner_pos + app_id + site_category + site_id + site_domain + device_type + device_conn_type\",\n",
    "#         featuresCol=\"features\",\n",
    "#         labelCol=\"label\")\n",
    "\t\tprint(type(FeatureString))\n",
    "\t\tformula = RFormula(formula=FeatureString,featuresCol=\"features\",labelCol=\"label\")\n",
    "\t\tformula_data = formula.fit(data).transform(data)\n",
    "\t\tformula_data.select(\"features\",\"label\").show()\n",
    "        #==\n",
    "        # Split the data into training and test sets (30% held out for testing)\n",
    "        #已經有了！\n",
    "        # Split training and test data.\n",
    "\t\t(training, test) = formula_data.randomSplit([0.7, 0.3], seed = 12345) #what's seed\n",
    "\t\ttraining.show()\n",
    "        #==\n",
    "        # Configure an ML pipeline, which consists of three stages: tokenizer, hashingTF, and rf (random forest).\n",
    "        #rf = RandomForestClassifier().setMaxBins(70)\n",
    "\t\trf = RandomForestClassifier(numTrees=100, maxDepth=20, labelCol=\"label\") #maxDepth=20, maxBins=64, \n",
    "\t\tpipeline = Pipeline(stages=[rf])\n",
    "\t\tpipelineModel = pipeline.fit(training)\n",
    "\t\ttrainingPredictions = pipelineModel.transform(training)\n",
    "        #trainingPredictions.show()\n",
    "\t\ttrainingPredictions.select(\"prediction\", \"label\", \"features\").show()\n",
    "\t\ttestPredictions = pipelineModel.transform(test)\n",
    "        #==\n",
    "\t\tevaluator = BinaryClassificationEvaluator()\n",
    "        #==\n",
    "\t\tevaluatorParaMap = {evaluator.metricName: \"areaUnderROC\"}\n",
    "\t\taucTraining = evaluator.evaluate(trainingPredictions, evaluatorParaMap)\n",
    "\t\taucTest = evaluator.evaluate(testPredictions, evaluatorParaMap)\n",
    "\t\tprint(\"pipeline Test AUC: %g\" % aucTest)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# #Cross validation (Do it later)\n",
    "# #==\n",
    "# #================================================\n",
    "# #Cross validation\n",
    "# from pyspark.ml.tuning import *\n",
    "# # The multiplies out to (2 x 3 x 3) x 10 = 180 different models being trained.\n",
    "# # k = 3 and k = 10 are common\n",
    "# #from pyspark.ml.tuning import *\n",
    "# #paramGrid = ParamGridBuilder().addGrid(rf.impurity, ['entropy', 'gini']).addGrid(rf.numTrees, [30, 50, 100]).build() #[10, 50, 100]高 50\n",
    "# paramGrid = ParamGridBuilder().addGrid(rf.maxDepth, [10,20,30]).addGrid(rf.impurity, ['entropy', 'gini']).addGrid(rf.numTrees, [30, 50, 100]).build()\n",
    "# #(rf.maxDepth, [10,20,30])\n",
    "# #println(paramGrid(1))\n",
    "\n",
    "# #=============#以上未做cv 以下做cv\n",
    "# cv = CrossValidator().setEstimator(pipeline).setEvaluator(evaluator).setEstimatorParamMaps(paramGrid).setNumFolds(3) #setNumFolds(3)\n",
    "# # Run cross-validation, and choose the best set of parameters.\n",
    "# cvModel = cv.fit(training)\n",
    "# cvPredictions = cvModel.transform(test)\n",
    "# cvAUCTest = evaluator.evaluate(cvPredictions, evaluatorParaMap)\n",
    "# cvPredictions.show()\n",
    "\n",
    "# #println(\"pipeline Training AUC: \" + aucTraining)\n",
    "# print(\"pipeline Test AUC: %g\" % aucTest)\n",
    "# print(\"Cross-Validation test AUC: %g\" % cvAUCTest)\n",
    "# #==\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
